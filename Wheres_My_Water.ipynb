{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqT7oHQ/LW4fUrTZtRJQpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AayeshaIslam/Where-s-My-Water/blob/main/Wheres_My_Water.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello! And welcome to our interactive Generative AI project titled Where's My Water? This project aims to address groundwater depletion and use generative AI to visualize and predict trends in groundwater depth in the United States.\n",
        "\n",
        "Why This is Important\n",
        "\n",
        "Water makes up 71% of the Earth, but of the water that's on Earth, only 3% of it is freshwater\n",
        "Of the freshwater that is on Earth, 68% of it is frozen, and only 30% of it is available as groundwater. This is what we typically rely on for drinking water.\n",
        "Human activity, such as sustained groundwater pumping and pollution can affect groundwater availability and groundwater quality. At the rate at which humans are using and treating groundwater, we predict that there may not be enough groundwater in the future\n",
        "What We're Doing\n",
        "\n",
        "Our project will first use the Stable Diffusion open source library, which is supported by the NVIDIA System Management Interface (SMI) to take in User Input and visualize what lakes and wells look like after groundwater depletion. Visualizing groundwater depletion is difficult, but it is important to note that surface water bodies rely on groundwater to replenish and maintain their water levels. We hope that having the providing visuals for the significance of groundwater depletion will help people realize the severity of this issue.\n",
        "Our project will also utilize USGS groundwater data from 1988 to 2022 to train our AI model to observe trends in groundwater for each state in the United States. We plan to create an interactive map and project groundwater trends in the country for future years.\n",
        "Visualizing Groundwater Depletion in Surface Water Bodies\n",
        "\n",
        "The following code utilizes the Stable Diffusion Open Source Library and NVIDIA SMI to generate AI images of wells and lakes experiencing groundwater depletion."
      ],
      "metadata": {
        "id": "90xG7tZ47Gyn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXWAsmAM6-cA"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi #to make this work, go to edit, notebook settings, and then change to gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.11.1\n",
        "!pip install transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "KorcskoX7N_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "AyDhuRyD7R49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "6PJA81bm7VtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = input(\"What would you like to visualize? Select A for lake after groundwater depletion or B for  well after groundwater depletion\")"
      ],
      "metadata": {
        "id": "UADG0wV87ZYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What would you like to visualize? Select A for lake after groundwater depletion or B for  well after groundwater depletionA"
      ],
      "metadata": {
        "id": "V7wkOjLw7hNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (val == 'A'):\n",
        "    prompt = \"Lake Mead after groundwater depletion\"\n",
        "if (val == 'B'):\n",
        "  prompt = \"Well after groundwater depletion\"\n",
        "\n",
        "image = pipe(prompt).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "# Now to display an image you can either save it such as:\n",
        "image.save(f\"visual.png\")\n",
        "\n",
        "# or if you're in a google colab you can directly display it with\n",
        "image"
      ],
      "metadata": {
        "id": "mXOv3yYc7jzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model with USGS Data\n",
        "\n",
        "The following block of code takes in USGS Groundwater Data from 1988 to 2022 and trains the AI Model to recognize patterns in groundwater depth by state and year\n",
        "The following section is for our Artificial Intelligence Model. We will take in groundwater data by state and year and train our model to predict trends in the groundwater depth."
      ],
      "metadata": {
        "id": "-Yn36u717sWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from CSV files\n",
        "state_data = pd.read_csv('/content/state_data - Sheet1.csv')\n",
        "groundwater_data = pd.read_csv('/content/groundwater_data - Sheet1.csv')\n",
        "\n",
        "# Extract features and target\n",
        "X = state_data\n",
        "y = groundwater_data\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Mean Squared Error on test set: {mse}')"
      ],
      "metadata": {
        "id": "PCYSKNpx7yLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample testing data\n",
        "sample_testing_data = pd.DataFrame({\n",
        "    'State': ['Florida'],\n",
        "    'Year': [2027]\n",
        "})\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "sample_X = pd.get_dummies(sample_testing_data)\n",
        "\n",
        "# Get missing columns in the sample testing data\n",
        "missing_cols = set(X.columns) - set(sample_X.columns)\n",
        "\n",
        "# Add the missing columns to the sample testing data\n",
        "for col in missing_cols:\n",
        "    sample_X[col] = 0\n",
        "\n",
        "# Reorder the columns to match the order of the training data\n",
        "sample_X = sample_X[X.columns]\n",
        "\n",
        "# Normalize the sample data\n",
        "sample_X_scaled = scaler.transform(sample_X)\n",
        "\n",
        "# Predict groundwater levels\n",
        "sample_predictions = model.predict(sample_X_scaled)\n",
        "\n",
        "# Print the predicted groundwater levels\n",
        "for state, prediction in zip(sample_testing_data['State'], sample_predictions):\n",
        "    print(f\"Predicted groundwater level for {state}: {prediction[0]}\")"
      ],
      "metadata": {
        "id": "rXGCQs2i759E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define a more complex model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "#mse = model.evaluate(X_test_scaled, y_test)\n",
        "#print(f'Mean Squared Error on test set: {mse}')\n",
        "\n",
        "# Make predictions on sample data\n",
        "sample_X_scaled = scaler.transform(sample_X)\n",
        "sample_predictions = model.predict(sample_X_scaled)\n",
        "\n",
        "# Print the predicted groundwater levels\n",
        "for state, prediction in zip(sample_testing_data['State'], sample_predictions):\n",
        "    my_groundwater_prediction = prediction[0]\n",
        "    my_state = state\n",
        "    print(f\"Predicted groundwater level for {state}: {prediction[0]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1qUqXMou8BAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code runs the website"
      ],
      "metadata": {
        "id": "e8M60qzV8D5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pyngrok==4.1.1\n",
        "!ngrok authtoken 2WnzUMGeErcRWbC7GeyRfumn473_645rVdoApCgT1FQd3kyBH"
      ],
      "metadata": {
        "id": "Y5KCcoX18EoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import earth engine\n",
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "FMquOAZu8LeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gVLMJnOu8O6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template_string\n",
        "from PIL import Image\n",
        "import io\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# Define a method for displaying Earth Engine image tiles to folium map.\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "    tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "    attr = 'Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "\n",
        "def ai_implement(year, state_name):\n",
        "\n",
        "\n",
        "  # Load the data from CSV files\n",
        "  state_data = pd.read_csv('/content/state_data - Sheet1.csv')\n",
        "  groundwater_data = pd.read_csv('/content/groundwater_data - Sheet1.csv')\n",
        "\n",
        "# Extract features and target\n",
        "  X = state_data\n",
        "  y = groundwater_data\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "  X = pd.get_dummies(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# TensorFlow and Keras\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "  #mse = model.evaluate(X_test_scaled, y_test)\n",
        "  #print(f'Mean Squared Error on test set: {mse}')\n",
        "\n",
        "  # Sample testing data\n",
        "  year_num = int(year)\n",
        "  sample_testing_data = pd.DataFrame({\n",
        "      'State': state_name,\n",
        "      'Year': year\n",
        "  })\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "  sample_X = pd.get_dummies(sample_testing_data)\n",
        "\n",
        "# Get missing columns in the sample testing data\n",
        "  missing_cols = set(X.columns) - set(sample_X.columns)\n",
        "\n",
        "# Add the missing columns to the sample testing data\n",
        "  for col in missing_cols:\n",
        "    sample_X[col] = 0\n",
        "\n",
        "# Reorder the columns to match the order of the training data\n",
        "  sample_X = sample_X[X.columns]\n",
        "\n",
        "# Normalize the sample data\n",
        "  sample_X_scaled = scaler.transform(sample_X)\n",
        "\n",
        "# Predict groundwater levels\n",
        "  sample_predictions = model.predict(sample_X_scaled)\n",
        "\n",
        "# Print the predicted groundwater levels\n",
        "  for state, prediction in zip(sample_testing_data['State'], sample_predictions):\n",
        "    print(f\"Predicted groundwater level for {state}: {prediction[0]}\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define a more complex model\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "# Compile the model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "  model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "  #mse = model.evaluate(X_test_scaled, y_test)\n",
        "  #print(f'Mean Squared Error on test set: {mse}')\n",
        "\n",
        "# Make predictions on sample data\n",
        "  sample_X_scaled = scaler.transform(sample_X)\n",
        "  sample_predictions = model.predict(sample_X_scaled)\n",
        "\n",
        "  my_groundwater_prediction = 0\n",
        "# Print the predicted groundwater levels\n",
        "  for state, prediction in zip(sample_testing_data['State'], sample_predictions):\n",
        "    my_groundwater_prediction = prediction[0]\n",
        "    my_state = state\n",
        "    print(f\"Predicted groundwater level for {state}: {prediction[0]}\")\n",
        "  return my_groundwater_prediction\n",
        "\n",
        "# Display the map.\n",
        "#display(my_map)\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "\n",
        "    fc = ee.FeatureCollection('TIGER/2018/States')\n",
        "    image = ee.Image().paint(fc, 0, 2)\n",
        "    # Add EE drawing method to folium.\n",
        "    folium.Map.add_ee_layer = add_ee_layer\n",
        "\n",
        "    # Create a folium map object.\n",
        "    my_map = folium.Map(location=[37.649, -99.844], zoom_start = 4)\n",
        "\n",
        "    # Add the layer to the map object.\n",
        "    my_map.add_ee_layer(image, {'palette': '00FFFF'}, 'TIGER/2018/States')\n",
        "\n",
        "    # Add a layer control panel to the map.\n",
        "    my_map.add_child(folium.LayerControl())\n",
        "\n",
        "    # Adds marker to\n",
        "    data = pd.DataFrame({\n",
        "        'lon':[-86.902298, -91.831833, -111.093731, -119.417932, -105.782067, -73.087749, -77.033418, -75.52767, -81.515754, -82.907123, -93.097702, -114.742041, -89.398528, -98.484246, -92.145024, -76.641271, -94.6859, -89.398528, -79.0193, -99.901813, -71.572395, -74.405661, -105.032363, -116.419389, -120.554201, -66.590149, -81.163725, -86.580447, -99.901813, -111.093731, -78.656894, -120.740139, -88.787868],\n",
        "        'lat':[32.318231, 35.20105, 34.048928, 36.778261, 39.550051, 41.603221, 38.905985, 38.910832, 27.664827, 32.157435, 41.878003, 44.068202, 40.633125, 39.011902, 31.244823, 39.045755, 46.729553, 32.354668, 35.759573, 41.492537, 43.193852, 40.058324, 34.97273, 38.80261, 43.804133, 18.220833, 33.836081, 35.517491, 31.968599, 39.32098, 37.431573, 47.751074, 43.78444],\n",
        "        'name':['Alabama', 'Arkansas', 'Arizona', 'California', 'Colorado', 'Connecticut', 'District of Columbia', 'Delaware','Florida', 'Georgia', 'Iowa', 'Idaho', 'Illinois', 'Kansas', 'Louisiana', 'Maryland', 'Minnesota', 'Mississippi', 'North Carolina', 'Nebraska', 'New Hampshire', 'New Jersey', 'New Mexico', 'Nevada', 'Oregon', 'Puerto Rico', 'South Carolina', 'Tennessee', 'Texas', 'Utah', 'Virginia', 'Washington', 'Wisconsin']\n",
        "    }, dtype=str)\n",
        "\n",
        "    data\n",
        "\n",
        "    for i in range (0, len(data)):\n",
        "      folium.Marker(\n",
        "        location=[data.iloc[i]['lat'], data.iloc[i]['lon']],\n",
        "        popup=data.iloc[i]['name'],\n",
        "      ).add_to(my_map)\n",
        "\n",
        "    #Do not add anything for the map ater this point\n",
        "    my_map.get_root().render()\n",
        "\n",
        "    #derive the script and style tags to be rendered in HTML head\n",
        "    header = my_map.get_root().header.render()\n",
        "\n",
        "    body_html = my_map.get_root().html.render()\n",
        "\n",
        "    script = my_map.get_root().script.render()\n",
        "\n",
        "    # Create a folium map object.\n",
        "    my_second_map = folium.Map(location=[37.649, -99.844], zoom_start = 4)\n",
        "    #Do not add anything for the map ater this point\n",
        "    my_second_map.get_root().render()\n",
        "\n",
        "    #derive the script and style tags to be rendered in HTML head\n",
        "    header2 = my_second_map.get_root().header.render()\n",
        "\n",
        "    body_html2 = my_second_map.get_root().html.render()\n",
        "\n",
        "    script2 = my_second_map.get_root().script.render()\n",
        "\n",
        "    info = None\n",
        "    if request.method=='POST':\n",
        "      year = request.form['year']\n",
        "      state= request.form['state']\n",
        "      info = ai_implement(year, state)\n",
        "\n",
        "      print(info)\n",
        "\n",
        "\n",
        "    return render_template_string(\"\"\"\n",
        "            <!DOCTYPE html>\n",
        "            <html>\n",
        "                <head>\n",
        "                    <title>Where's My Water!</title>\n",
        "                    {{ header|safe }}\n",
        "                </head>\n",
        "                <body class=\"bg-info text-white\">\n",
        "                <div class=\"text-center\">\n",
        "                    <h1 class=\"mt-5\"><b>Where's My Water!</b></h1>\n",
        "                    <h3 class=\"mb-5\">Type below to interact with our chatbot</h3>\n",
        "                    <form action=\"/\" method=\"post\">\n",
        "                      <input type=\"text\" id=\"year\" name=\"year\" placeholder=\"Year\" class=\"mb-5\">\n",
        "                      <input type=\"text\" id=\"state\" name=\"state\" placeholder=\"State\" class=\"mb-5\">\n",
        "                      <button>Enter</button>\n",
        "                    </form>\n",
        "                    {% if info %}\n",
        "                    {{ info }}\n",
        "                    {% endif %}\n",
        "                </div>\n",
        "                    {{ body_html|safe }}\n",
        "                    <script>\n",
        "                        {{ script|safe }}\n",
        "\n",
        "\n",
        "                    </script>\n",
        "\n",
        "                </body>\n",
        "            </html>\n",
        "        \"\"\",\n",
        "        header=header,\n",
        "        body_html=body_html,\n",
        "        script=script, data=data)\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "id": "-OB3dsU68PyG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}